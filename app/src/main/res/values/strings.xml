<resources>
    <string name="app_name">ComputerArchitecture</string>
    <string name="multithreading">Multithreading</string>
    <string name="computer_architecture">Computer Architecture</string>
    <string name="static_scheduling_name">Static Scheduling</string>
    <string name="static_scheduling_description">The Compiler can attempt to schedule instructions. </string>
    <string name="dynamic_scheduling_name">Dynamic scheduling</string>
    <string name="dynamic_scheduling_description">The Hardware rearranges the instruction execution to reduce the
        stalls.</string>
    <string name="as_soon_as_possible_name">As soon as possible (ASAP)</string>
    <string name="as_soon_as_possible_description">Executes instructions as soon as possible.</string>
    <string name="as_late_as_possible_name">As late as possible(ALAP)</string>
    <string name="as_late_as_possible_description">Executes instructions as late as possible.</string>

    <string name="cgmt_description">Change threads in case of longer delays.</string>
    <string name="cgmt_advantages"> Small delay can be tolerated when switching threads.
        Critical threads can be prioritized.</string>
    <string name="cgmt_disadvantages">Short stalls must be tolerated.</string>

    <string name="fgmt_description">Change threads with each instruction.</string>
    <string name="fgmt_advantages">Any processor availability can be used.</string>
    <string name="fgmt_disadvantages">Higher latency of individual threads.</string>

    <string name="smt_description">Multiple threads can be executed simultaneously on one CPU core.</string>
    <string name="smt_advantages">Instructions from different,
        independent threads can be executed simultaneously.</string>
    <string name="smt_disadvantages">Higher latency of individual threads, higher implementation effort</string>

    <string name="advantages">Advantages</string>
    <string name="disadvantages">Disadvantages</string>
    <string name="simultaneous_multithreading">Simultaneous Multithreading</string>
    <string name="fine_grained_multithreading">Fine-grained Multithreading</string>
    <string name="coarse_grained_multithreading">Coarse-grained Multithreading</string>
    <string name="hardware_layer">Hardware Layer</string>
    <string name="software_layer">Software Layer</string>
    <string name="speedup">Speedup</string>
    <string name="speedup_exercise_description">
        A sequential program can be divided into 5 parts A to E, which must be
    executed in this order due to their dependencies. The table lists the amount of run-time each part contributes to
    the run-time of the program. Parts A, C and E cannot be parallelized. Part B can be transformed in max. 16
        sub-parts that can be executed in parallel. For the parallel execution of part D, no restrictions exist.</string>

    <string name="part">Part</string>
    <string name="multiprocessor_systems">Multiprocessor Systems</string>
    <string name="numa_title_short">NUMA</string>
    <string name="numa_title_long">Non-Uniform-Memory-Access</string>
    <string name="numa_runtime_description">"Memory access time depends on the memory location relative to the processor. Memory may be local, one hop away, or two hops away. "</string>
    <string name="gpus">Graphics Processing Units</string>
    <string name="open_cl">OpenCL</string>
    <string name="posix_threads">POSIX Threads</string>
    <string name="includes">Includes</string>
    <string name="pthread_include"><![CDATA[#include <pthread.h>]]></string>

    <string name="thread_create">Thread Create</string>
    <string name="pthread_create">pthread_create(thread, attr, start_routine, arg)</string>
    <string name="thread_exit">Thread Exit</string>
    <string name="pthread_exit">pthread_exit(status)</string>
    <string name="thread_join">Thread Join</string>
    <string name="pthread_join">pthread_join(thread, status)</string>
    <string name="thread_cancel">Thread Cancel</string>
    <string name="pthread_cancel">pthread_cancel(thread)</string>
    <string name="thread_mutex_init">Thread Mutex Init</string>
    <string name="pthread_mutex_init">pthread_mutex_init(mutex, attr)</string>
    <string name="thread_mutex_destroy">Thread Mutex Destroy</string>
    <string name="pthread_mutex_destroy">pthread_mutex_destroy(mutex)</string>
    <string name="thread_mutex_lock">Thread Mutex Lock</string>
    <string name="pthread_mutex_lock">pthread_mutex_lock(mutex)</string>
    <string name="thread_mutex_unlock">Thread Mutex Unlock</string>
    <string name="pthread_mutex_unlock">pthread_mutex_unlock(mutex)</string>
    <string name="thread_condition_init">Thread Condition Init</string>
    <string name="pthread_cond_init">pthread_cond_init(cond, attr)</string>
    <string name="thread_condition_wait">Thread Condition Wait</string>
    <string name="pthread_cond_wait">pthread_cond_wait(cond, mutex)</string>
    <string name="thread_condition_signal">Thread Condition Signal</string>
    <string name="pthread_cond_signal">pthread_cond_signal(cond)</string>

    <string name="thread">thread</string>
    <string name="attr">attr</string>
    <string name="start_routine">start_routine</string>
    <string name="arg">arg</string>
    <string name="pthread_create_description">Creates a new thread and makes it executable. </string>
    <string name="thread_description">An opaque, unique identifier for the new thread returned by the
        subroutine.</string>
    <string name="attr_description">An opaque attribute object that may be used to set thread attributes.
        You can specify a thread attributes object, or NULL for the default values.</string>
    <string name="start_routine_description">The C routine that the thread will execute once it is created.</string>
    <string name="arg_description">A single argument that may be passed to start_routine.
        It must be passed by reference as (void *).NULL may be used if no argument is to be passed.</string>
    <string name="caching">Caching</string>
    <string name="average_runtimes">Average Runtimes</string>
    <string name="block_placement">Block Placement</string>
    <string name="block_identification">Block Identification</string>
    <string name="block_replacement">Block Replacement</string>
    <string name="write_strategy">Write Strategy</string>
    <string name="block_placement_question">Where can a memory block be stored in the cache?</string>
    <string name="navigate_to">Navigate to</string>
    <string name="block_identification_question">How is a memory block found?</string>
    <string name="block_replacement_question">Which block should be replaced in the event of a failed access (cache miss)?</string>
    <string name="write_strategy_question">What happens when data is written to the cache?</string>
    <string name="direct_mapping_block_placement">Each block can be placed at exactly one location in the cache.</string>
    <string name="direct_mapping">Direct Mapping</string>
    <string name="set_associative_mapping">Set Associative Mapping</string>
    <string name="set_associative_mapping_block_placement">Each block can be placed at a restricted set of locations in the cache.</string>
    <string name="associative_mapping">Associative Mapping</string>
    <string name="associative_mapping_block_placement">Each block can be placed at any location in the cache.</string>
    <string name="tag">Tag</string>
    <string name="tag_description">The tag contains the most significant bits of the address, which are checked against
        all rows in the current set to see if this set contains the requested
        address. </string>
    <string name="tag_length"> tag_length = address_length - index_length - offset_length</string>
    <string name="index">Index</string>
    <string name="index_description">The index describes which cache set that the data has been put in.</string>
    <string name="index_length"> index_length = ceil(log_2(s)), for s cache sets </string>
    <string name="offset">Offset</string>
    <string name="offset_description">The block offset specifies the desired data within the stored data block within
        the cache row.</string>
    <string name="offset_length">offset_length = ceil(log_2(b)), for b bytes per block </string>
    <string name="direct_mapping_block_identification">Tag, index and offset</string>
    <string name="set_associative_mapping_block_identification">Tag, index and offset  </string>
    <string name="associative_mapping_block_identification">Tag and index</string>
    <string name="direct_mapping_block_replacement">Only one block is checked for a hit, and only that block can be replaced.</string>
    <string name="set_associative_mapping_block_replacement">Random/LRU/FIFO/Clock</string>
    <string name="associative_mapping_block_replacement">Random/LRU/FIFO/Clock</string>
    <string name="random">Random</string>
    <string name="random_description">Candidate blocks are randomly selected.</string>
    <string name="lru">Least recently used (LRU)</string>
    <string name="lru_description">The block replaced is the one that has been unused for the longest time.</string>
    <string name="fifo">First in, first out (FIFO)</string>
    <string name="fifo_description">The block replaced is the oldest block.</string>
    <string name="clock">Clock</string>
    <string name="clock_description">Search for block with used bit = \'0\' and reset the bit at the same time. Stop
        after max. 1 round.</string>
    <string name="write_allocate">Write allocate</string>
    <string name="write_allocate_description">The block is allocated on a write miss.</string>
    <string name="no_write_allocate_description">Write misses do not affect the cache. Instead, the block is modified only in the lower-level memory.</string>
    <string name="no_write_allocate">No-write allocate</string>
    <string name="branch_prediction">Branch Prediction</string>
    <string name="one_bit_predictors_description">
        Contain 1 bit: Jump executed last time (taken) or not (not taken)\nPrediction: jump behaves as it did last time
    </string>
    <string name="on_bit_predictors">1-bit Predictors</string>
    <string name="local_predictors">Local Predictors</string>
    <string name="two_bit_predictors">2-bit Predictors</string>
    <string name="thread_management">Thread Management</string>
    <string name="mutex_variables">Mutex Variables</string>
    <string name="condition_variables">Condition Variables</string>
    <string name="open_mp">OpenMP</string>
    <string name="parallel_directive">Parallel Directive</string>
    <string name="parallel_syntax">#pragma omp parallel</string>
    Instructs the master thread to
    <string name="parallel_description">Tells the master thread to fork and create a team of threads.</string>
    <string name="parallel_for_pragma_description">Compiler will automatically assign loop iterations to parallel threads.
        \nclauses : nowait, order, ordered, private, reduction, schedule</string>
    <string name="pragma_omp_parallel_for">#pragma omp parallel for</string>
    <string name="library_functions">Library Functions</string>
    <string name="set_num_threads">omp_set_num_threads(num_threads)</string>
    <string name="set_num_threads_description">Affects the number of threads to be used for subsequent parallel regions that do not specify a num_threads clause.</string>
    <string name="get_num_threads">omp_get_num_threads()</string>
    <string name="get_num_threads_description">Returns the number of threads in the current team.</string>
    <string name="get_thread_num">omp_get_thread_num()</string>
    <string name="get_thread_num_description">Returns the thread number, within the current team, of the calling thread.</string>
    <string name="schedule_syntax">schedule(schedule_kind, chunk_size)</string>
    <string name="schedule_pragma_description">schedule_kind can be static, dynamic, guided, auto or runtime.</string>
    <string name="pragma_omp_critical">#pragma omp critical</string>
    <string name="pragma_omp_critical_description">Restricts execution of the associated structured block to a single thread at a time.</string>
    <string name="pragma_omp_atomic">#pragma omp atomic</string>
    <string name="pragma_omp_atomic_description">Ensures a specific storage location is accessed atomically.</string>
    <string name="data_sharing_clauses">Data Sharing Clauses</string>
    <string name="default_syntax">default (shared | private | none)</string>
    <string name="default_description">shared: All variables shared by default.\nprivate: All variables private by default.\nnone: Sharing mode for each variable must be explicitly stated.</string>
    <string name="shared_syntax">shared (list)</string>
    <string name="shared_description">Variables in list are shared between threads or explicit tasks executing the construct.</string>
    <string name="private_syntax">private (list)</string>
    <string name="private_description">Creates a new variable for each item in list that is private to each thread or explicit task. The private variable is not given an initial value.</string>
    <string name="reduction_clause">Reduction Clause</string>
    <string name="reduction_syntax">reduction (operator : variable_name)</string>
    <string name="reduction_description">At join, local variables are combined and assigned to shared variable.
        \noperator : +, *, &amp;, |, ^, &amp;&amp; or ||
    </string>
    <string name="barrier_syntax">#pragma omp barrier</string>
    <string name="barrier_description">Threads will wait until all threads have reached the barrier.</string>
    <string name="synchronization_constructs">Synchronization Constructs</string>
    <string name="no_wait_syntax">nowait</string>
    <string name="no_wait_description">"Overrides any synchronization that would otherwise occur at the end of a construct. "</string>
    <string name="no_wait_clause">No Wait Clause</string>
    <string name="order_clause">Order Clause</string>
    <string name="ordered_syntax">#pragma omp ordered</string>
    <string name="order_description">The ordered clause can be used to control the order of some operations within a loop.</string>
    <string name="work_sharing_constructs">Work Sharing Constructs</string>
    <string name="sections_syntax">#pragma omp sections</string>
    <string name="sections_description">A non-iterative work sharing construct that contains a set of structured blocks
        that are to be distributed among and executed by the threads in a team.\n
        #pragma omp sections\n\t
            {\n\t
                #pragma omp section\n\t\t\t\t
                    structured-block-sequence\n\t
                #pragma omp section\n\t\t\t\t
                    structured-block-sequence\n\t
            …\n\t
        }

    </string>
    <string name="single_syntax">#pragma omp single</string>
    <string name="single_description">Some thread will run it.</string>
    <string name="master_syntax">#pragma omp master</string>
    <string name="master_description">The master thread will run it.</string>
    <string name="schedule_clause">Schedule Clause</string>

</resources>