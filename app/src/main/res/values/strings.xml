<resources>
    <string name="app_name">ComputerArchitecture</string>
    <string name="multithreading">Multithreading</string>
    <string name="computer_architecture">Computer Architecture</string>
    <string name="static_scheduling_name">Static Scheduling</string>
    <string name="static_scheduling_description">The Compiler can attempt to schedule instructions. </string>
    <string name="dynamic_scheduling_name">Dynamic scheduling</string>
    <string name="dynamic_scheduling_description">The Hardware rearranges the instruction execution to reduce the
        stalls.</string>
    <string name="as_soon_as_possible_name">As soon as possible (ASAP)</string>
    <string name="as_soon_as_possible_description">Executes instructions as soon as possible.</string>
    <string name="as_late_as_possible_name">As late as possible(ALAP)</string>
    <string name="as_late_as_possible_description">Executes instructions as late as possible.</string>
    <string name="cgmt_description">Change threads in case of longer delays.</string>
    <string name="cgmt_advantages"> Small delay can be tolerated when switching threads.
        Critical threads can be prioritized.</string>
    <string name="cgmt_disadvantages">Short stalls must be tolerated.</string>
    <string name="fgmt_description">Change threads with each instruction.</string>
    <string name="fgmt_advantages">Any processor availability can be used.</string>
    <string name="fgmt_disadvantages">Higher latency of individual threads.</string>
    <string name="smt_description">Multiple threads can be executed simultaneously on one CPU core.</string>
    <string name="smt_advantages">Instructions from different,
        independent threads can be executed simultaneously.</string>
    <string name="smt_disadvantages">Higher latency of individual threads, higher implementation effort</string>
    <string name="advantages">Advantages</string>
    <string name="disadvantages">Disadvantages</string>
    <string name="simultaneous_multithreading">Simultaneous Multithreading</string>
    <string name="fine_grained_multithreading">Fine-grained Multithreading</string>
    <string name="coarse_grained_multithreading">Coarse-grained Multithreading</string>
    <string name="hardware_layer">Hardware Layer</string>
    <string name="software_layer">Software Layer</string>
    <string name="speedup">Speedup</string>
    <string name="speedup_exercise_description">
        A sequential program can be divided into 5 parts A to E, which must be
    executed in this order due to their dependencies. The table lists the amount of run-time each part contributes to
    the run-time of the program. Parts A, C and E cannot be parallelized. Part B can be transformed in max. 16
        sub-parts that can be executed in parallel. For the parallel execution of part D, no restrictions exist.</string>
    <string name="part">Part</string>
    <string name="multiprocessor_systems">Multiprocessor Systems</string>
    <string name="numa_title_short">NUMA</string>
    <string name="numa_title_long">Non-Uniform-Memory-Access</string>
    <string name="numa_runtime_description">"Memory access time depends on the memory location relative to the processor. Memory may be local, one hop away, or two hops away. "</string>
    <string name="gpus">Graphics Processing Units</string>
    <string name="open_cl">OpenCL</string>
    <string name="posix_threads">POSIX Threads</string>
    <string name="pthread_exit">pthread_exit(status)</string>
    <string name="pthread_join">pthread_join(thread, status)</string>
    <string name="pthread_cancel">pthread_cancel(thread)</string>
    <string name="pthread_mutex_init">pthread_mutex_init(mutex, attr)</string>
    <string name="pthread_mutex_destroy">pthread_mutex_destroy(mutex)</string>
    <string name="pthread_mutex_lock">pthread_mutex_lock(mutex)</string>
    <string name="pthread_mutex_unlock">pthread_mutex_unlock(mutex)</string>
    <string name="pthread_cond_init">pthread_cond_init(cond, attr)</string>
    <string name="pthread_cond_signal">pthread_cond_signal(cond)</string>
    <string name="pthread_cond_wait">pthread_cond_wait(cond, mutex)</string>
    <string name="thread">thread</string>
    <string name="attr">attr</string>
    <string name="start_routine">start_routine</string>
    <string name="arg">arg</string>
    <string name="pthread_create">pthread_create(thread, attr, start_routine, arg)</string>
    <string name="pthread_create_description">Creates a new thread executing start_routine with arg as its argument.
    </string>
    <string name="thread_description">An opaque, unique identifier for the new thread returned by the
        subroutine.</string>
    <string name="attr_description">An opaque attribute object that may be used to set thread attributes.
        You can specify a thread attributes object, or NULL for the default values.</string>
    <string name="start_routine_description">The C routine that the thread will execute once it is created.</string>
    <string name="arg_description">A single argument that may be passed to start_routine.
        It must be passed by reference as (void *).NULL may be used if no argument is to be passed.</string>
    <string name="caching">Caching</string>
    <string name="block_placement">Block Placement</string>
    <string name="block_identification">Block Identification</string>
    <string name="block_replacement">Block Replacement</string>
    <string name="write_strategy">Write Strategy</string>
    <string name="block_placement_question">Where a memory block can be stored in the cache</string>
    <string name="navigate_to">Navigate to</string>
    <string name="block_identification_question">How a memory block is found</string>
    <string name="block_replacement_question">Which block should be replaced in the event of a failed access (cache miss)</string>
    <string name="write_strategy_question">What happens when data is written to the cache</string>
    <string name="direct_mapping_block_placement">Each block can be placed at exactly one location in the cache.</string>
    <string name="direct_mapping">Direct Mapping</string>
    <string name="set_associative_mapping">Set Associative Mapping</string>
    <string name="set_associative_mapping_block_placement">Each block can be placed at a restricted set of locations in the cache.</string>
    <string name="associative_mapping">Associative Mapping</string>
    <string name="associative_mapping_block_placement">Each block can be placed at any location in the cache.</string>
    <string name="tag">Tag</string>
    <string name="tag_description">The tag contains the most significant bits of the address, which are checked against
        all rows in the current set to see if this set contains the requested
        address. </string>
    <string name="tag_length"> tag_length = address_length - index_length - offset_length</string>
    <string name="index">Index</string>
    <string name="index_description">The index describes which cache set that the data has been put in.</string>
    <string name="index_length"> index_length = ceil(log_2(s)), for s cache sets </string>
    <string name="offset">Offset</string>
    <string name="offset_description">The block offset specifies the desired data within the stored data block within
        the cache row.</string>
    <string name="offset_length">offset_length = ceil(log_2(b)), for b bytes per block </string>
    <string name="direct_mapping_block_identification">Tag, index and offset</string>
    <string name="set_associative_mapping_block_identification">Tag, index and offset  </string>
    <string name="associative_mapping_block_identification">Tag and index</string>
    <string name="direct_mapping_block_replacement">Only one block is checked for a hit, and only that block can be replaced.</string>
    <string name="set_associative_mapping_block_replacement">Random/LRU/FIFO/Clock</string>
    <string name="associative_mapping_block_replacement">Random/LRU/FIFO/Clock</string>
    <string name="random">Random</string>
    <string name="random_description">Candidate blocks are randomly selected.</string>
    <string name="lru">Least recently used (LRU)</string>
    <string name="lru_description">The block replaced is the one that has been unused for the longest time.</string>
    <!-- LRU Linked List -->
    <string name="lru_linked_list_data_structure">Linked list of entries, sorted by order of access</string>
    <string name="lru_linked_list_access">Access to entry i</string>
    <string name="lru_linked_list_access_description">i is inserted at the beginning of the list and any other
        occurrences of i are removed from the list.</string>
    <string name="lru_linked_list_supplanting">Supplanting an entry</string>
    <string name="lru_linked_list_supplanting_description">The entry belonging to the last element in the list is overwritten.</string>
    <string name="fifo">First in, first out (FIFO)</string>
    <string name="fifo_description">The block replaced is the oldest block.</string>
    <string name="clock">Clock</string>
    <string name="clock_description">Search for block with used bit = \'0\' and reset the bit at the same time. Stop
        after max. 1 round.</string>
    <string name="write_allocate">Write allocate</string>
    <string name="write_allocate_description">The block is allocated on a write miss.</string>
    <string name="no_write_allocate_description">Write misses do not affect the cache. Instead, the block is modified only in the lower-level memory.</string>
    <string name="no_write_allocate">No-write allocate</string>
    <string name="branch_prediction">Branch Prediction</string>
    <string name="one_bit_predictors_description">
        Contain 1 bit: Jump executed last time (taken) or not (not taken)\nPrediction: Jump behaves as it did last time
    </string>
    <string name="one_bit_predictors">1-Bit Predictors</string>
    <string name="two_bit_predictors">2-Bit Predictors</string>
    <string name="n_bit_predictors">n-Bit Predictors</string>
    <string name="n_bit_predictors_description">Values between 0 and (2^n)-1\nPrediction: If counter > ((2^n) - 1)/2
        then jump will be executed.\nCounter is incremented when a jump is executed and decremented when not.</string>
    <string name="local_predictors">Local Predictors</string>
    <string name="correlating_predictors">Correlating Predictors</string>
    <string name="correlating_predictors_description">Look at behavior of the last m jumps to select an n-bit predictor from 2^n local predictors.</string>
    <string name="tournament_predictors">Tournament Predictors</string>
    <string name="tournament_predictors_description">Use of multiple predictors and selection from them, usually a
        combination of local and global predictors.</string>
    <string name="thread_management">Thread Management</string>
    <string name="mutex_variables">Mutex Variables</string>
    <string name="condition_variables">Condition Variables</string>
    <string name="open_mp">OpenMP</string>
    Instructs the master thread to
    <string name="clauses">Clauses</string>
    <string name="parallel_description">Tells the master thread to fork and create a team of threads.</string>
    <string name="for_description">Compiler will automatically assign loop iterations to parallel threads.</string>
    <string name="functions">Functions</string>
    <string name="set_num_threads">omp_set_num_threads(num_threads)</string>
    <string name="set_num_threads_description">Affects the number of threads to be used for subsequent parallel regions that do not specify a num_threads clause.</string>
    <string name="get_num_threads">omp_get_num_threads()</string>
    <string name="get_num_threads_description">Returns the number of threads in the current team.</string>
    <string name="get_thread_num">omp_get_thread_num()</string>
    <string name="get_thread_num_description">Returns the thread number, within the current team, of the calling thread.</string>
    <string name="schedule_pragma_description">schedule_kind can be static, dynamic, guided, auto or runtime.</string>
    <string name="pragma_omp_critical_description">Restricts execution of the associated structured block to a single thread at a time.</string>
    <string name="pragma_omp_atomic_description">Ensures a specific storage location is accessed atomically.</string>
    <string name="data_sharing_clauses">Data Sharing Clauses</string>
    <string name="default_syntax">default (shared | private | none)</string>
    <string name="default_description">shared: All variables shared by default.\nprivate: All variables private by default.\nnone: Sharing mode for each variable must be explicitly stated.</string>
    <string name="shared_syntax">shared (list)</string>
    <string name="shared_description">Variables in list are shared between threads or explicit tasks executing the construct.</string>
    <string name="private_syntax">private (list)</string>
    <string name="private_description">Creates a new variable for each item in list that is private to each thread or explicit task. The private variable is not given an initial value.</string>
    <string name="reduction_clause">Reduction Clause</string>
    <string name="reduction_syntax">reduction (operator:var_name)</string>
    <string name="reduction_description">At join, local variables are combined and assigned to shared variable.
        \noperator : +, *, &amp;, |, ^, &amp;&amp; or ||
    </string>

    <string name="barrier_description">Threads will wait until all threads have reached the barrier.</string>
    <string name="synchronization_constructs">Synchronization Constructs</string>
    <string name="no_wait_syntax">nowait</string>
    <string name="no_wait_description">"Overrides any synchronization that would otherwise occur at the end of a construct. "</string>
    <string name="no_wait_clause">No Wait Clause</string>
    <string name="order_clause">Order Clause</string>
    <string name="order_description">Can be used to control the order of some operations within a loop.</string>
    <string name="work_sharing_constructs">Work Sharing Constructs</string>
    <string name="sections_description">A non-iterative work sharing construct that contains a set of structured blocks
        that are to be distributed among and executed by the threads in a team.
    </string>
    <string name="single_description">Some thread will run it.</string>
    <string name="master_description">The master thread will run it.</string>
    <string name="message_passing_interface">Message Passing Interface</string>
    <string name="send_syntax">MPI_Send ( address, count, data_type, destination, tag, comm )</string>
    <string name="send_description">
        address: Starting memory address of elements to send
        \ncount: Number of elements to send
        \ndata_type: Datatype of elements to send
        \ndestination: Memory address to send elements to
        \ntag: Integer for message matching
        \ncomm: Communication context
    </string>
    <string name="receive_syntax">MPI_Recv ( address, max_count, data_type, source, tag, comm, status )</string>
    <string name="receive_description">
        address: Starting memory address of elements to receive
        \nmax_count: Maximum number of elements to receive
        \ndata_type: Datatype of elements to receive
        \nsource: Memory address to receive elements from
        \ntag: Integer for message matching
        \ncomm: Communication context
        \nstatus: Return parameter with information about actual size, source, and tag
    </string>
    <string name="data_types">Data Types</string>
    <string name="data_types_description">MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG</string>
    <string name="derived_data_types">Derived Data Types</string>
    <string name="derived_data_types_description">Sequence of basic data types.</string>
    <string name="communication_patterns">Communication Patterns</string>
    <string name="mpi_bcast">MPI_Bcast ()</string>
    <string name="mpi_bcast_description">Broadcasts data to a group of processes.</string>
    <string name="mpi_reduce_description">Collects and reduces data.</string>
    <string name="mpi_reduce">MPI_Reduce ()</string>
    <string name="mpi_scatter">MPI_Scatter ()</string>
    <string name="mpi_scatter_description">Distributes an array of data; one piece to every process.</string>
    <string name="mpi_gather">MPI_Gather ()</string>
    <string name="mpi_gather_description">Collects an array of data; one piece from every process.</string>
    <string name="mpi_all_reduce">MPI_Allreduce ()</string>
    <string name="mpi_all_reduce_description">MPI_Reduce () plus MPI_Bcast ()</string>
    <string name="mpi_all_gather">MPI_Allgather ()</string>
    <string name="mpi_all_gather_description">MPI_Gather () plus MPI_Bcast ()</string>
    <string name="mpi_barrier_description">Wait for all processes to reach the barrier.</string>
    <string name="mpi_barrier">MPI_Barrier ()</string>
    <string name="speedup_calculator">Speedup Calculator</string>
    <string name="amdahls_law">Amdahl\'s Law</string>
    <string name="amdahls_law_formula">S_tot = 1 / ((1 - P) + P / N)</string>
    <string name="amdahls_law_description">
        Assumes that the problem size remains constant, regardless of the number of processors.
    </string>
    <string name="gustafsons_law">Gustafson\'s Law</string>
    <string name="gustafsons_law_formula">S\'_tot = (1 - P) + P * N</string>
    <string name="gustafsons_law_description">
    Assumes that the problem size grows linearly with the number of processors.
    </string>
    <string name="send_api">Send API</string>
    <string name="receive_api">Receive API</string>
    <string name="instruction_scheduling">Instruction Scheduling</string>
    <string name="energy_efficiency">Energy Efficiency</string>
    <string name="memory_hierarchy">Memory Hierarchy</string>
    <string name="networks">Networks</string>
    <string name="reliability">Reliability</string>
    <string name="flynns_taxonomy">Flynn\'s Taxonomy</string>
    <string name="tertiary_storage">Tertiary Storage</string>
    <string name="secondary_storage">Secondary Storage</string>
    <string name="disk_caches">Disk Caches</string>
    <string name="primary_memory">Main or Primary Memory</string>
    <string name="caches_tlbs">Caches</string>
    <string name="registers">Registers</string>
    <string name="cache_coherence">Cache Coherence</string>
    <string name="cache_coherence_description">Uniformity of shared resource data in multiple local caches.</string>
    <string name="maintenance">Maintenance</string>
    <string name="snooping_based_coherence">Snooping-Based Coherence</string>
    <string name="snooping_based_coherence_description">All processors communicate to agree on item states.</string>
    <string name="directory_based_coherence">Directory-Based Coherence</string>
    <string name="directory_based_coherence_description">A centralized directory holds information about state/whereabouts of data items.</string>
    <string name="cache_definition">Definition</string>
    <string name="computation_model">Computation Model</string>
    <string name="open_cl_computation_model_description">Kernels that execute on one or more OpenCL devices and a host program that executes on the host</string>
    <string name="open_cl_program_components">Program Components</string>
    <string name="open_cl_program_components_description">Kernels, auxiliary functions and constant data</string>
    <string name="portability">Portability</string>
    <string name="open_cl_portability_description">Via its abstracted memory and execution model</string>
    <string name="memory_model">Memory Model</string>
    <string name="open_cl_memory_model_description">Memory regions, Memory objects, Shared Virtual Memory, Consistency Model</string>
    <string name="sisd">Single Instruction Stream, Single Data Stream (SISD)</string>
    <string name="sisd_description">Corresponds to the classical uni-processor system.</string>
    <string name="simd">Single Instruction Stream, Multiple Data Streams (SIMD)</string>
    <string name="simd_description">Own data memory per processor, but shared instruction memory and control unit.</string>
    <string name="misd">Multiple Instruction Streams, Single Data Stream (MISD)</string>
    <string name="misd_description">Multiple processors execute different instructions but operate on the same data stream.</string>
    <string name="mimd">Multiple Instruction Streams, Multiple Data Streams (MIMD)</string>
    <string name="mimd_description">Each processor processes its own instruction and data stream.</string>
    <string name="msi_protocol">MSI Protocol</string>
    <string name="data_parallelism">Dara Parallelism</string>
    <string name="executing_kernels">Executing Kernels</string>
    <string name="cl_enqueue_nd_range_kernel">clEnqueueNDRangeKernel</string>
    <string name="cl_enqueue_nd_range_kernel_description">Enqueues a command to execute a kernel on a device.</string>
    <string name="work_item_functions">Work-Item Functions</string>
    <string name="get_global_id">get_global_id(uint dimindx)</string>
    <string name="get_global_id_description">Returns the unique global work-item ID for the specified dimension dimindx.</string>
    <string name="spectre">Spectre</string>
    <string name="spectre_attacks">Spectre Attacks</string>
    <string name="spectre_attacks_description">Access data from other processes or the operating system, by performing
        otherwise illegal memory access speculatively, and then extract data via a hidden channel.
    </string>
    <string name="spectre_attacks_step_one">1.Speculative Access</string>
    <string name="spectre_attacks_step_one_example"><![CDATA[const otherArray = [\'notPrivate\', \'privateData1\'];\nif (i < 1) {\n  // Will be executed speculatively even when i >= 1\n  someVariable = someArray[i];\n  tmp = otherArray[(someVariable>>bit)&1];\n}]]></string>
    <string name="spectre_attacks_step_two">2.Secret-dependent Memory Access</string>
    <string name="spectre_attacks_step_two_example"><![CDATA[const otherArray = [\'notPrivate\', \'privateData1\'];\nif (i < 1) {\n  someVariable = someArray[i];\n  //Extracts one bit of the read value\n  tmp = otherArray[(someVariable>>bit)&1];\n}]]></string>
    <string name="spectre_attacks_step_three">3.Reading out the transmitted Data</string>
    <string name="spectre_attacks_step_three_example"><![CDATA[//Cache hit in case that the extracted bit was 0.\ntime = rdtsc();\nmemory_access(&otherArray[0]);\nvar delta0 = rdtsc() - time;\n//Cache hit in case that the extracted bit was 1.\ntime = rdtsc();\nmemory_access(&otherArray[1]);\nvar delta1 = rdtsc() - time;]]></string>
    <string name="pthread_exit_description">Terminates the calling thread.</string>
    <string name="pthread_join_description">Suspends execution of the calling thread until the target thread terminates.</string>
    <string name="pthread_cancel_description">Requests thread to be canceled.</string>
    <string name="pthread_mutex_init_description">Initializes the mutex referenced by mutex with attributes specified  by  attr.</string>
    <string name="pthread_mutex_destroy_description">Destroys  the  mutex  object referenced  by  mutex.</string>
    <string name="pthread_mutex_lock_description">Locks the object referenced by mutex.</string>
    <string name="pthread_mutex_unlock_description">Releases the mutex object referenced by mutex.</string>
    <string name="pthread_cond_init_description">Initializes the condition variable referenced by cond with attributes referenced by attr.</string>
    <string name="pthread_cond_signal_description">Unblocks at least one of the threads that are blocked on the specified condition variable cond.</string>
    <string name="pthread_cond_wait_description">Blocks the calling thread until the specified condition cond is signaled.</string>
    <string name="branch_target_buffer">Branch Target Buffer</string>
    <string name="branch_target_buffer_description">A structure that caches the destination programm counter or destination instruction for a branch.</string>
    <string name="steps_in_the_pipeline">Steps in the Pipeline</string>
    <string name="return_address_buffer">Return Address Buffer</string>
    <string name="return_address_buffer_description">Stack memory for return addresses\nPush on procedure call and pop on return.</string>
    <string name="function_qualifiers">Function Qualifiers</string>
    <string name="kernel">__kernel</string>
    <string name="kernel_description">Declares a function to be a kernel that can be executed by an application on an OpenCL device(s).</string>
    <string name="open_cl_barrier_syntax">barrier(flags)</string>
    <string name="open_cl_barrier_description">Blocks until all threads in the group have reached the barrier. Also enforces memory ordering.</string>
    <string name="open_cl_mem_fence_syntax">mem_fence(flags)</string>
    <string name="open_cl_mem_fence_description">Enforces memory ordering: all memory operations are committed before thread continues.</string>
    <string name="thread_synchronization">Thread Synchronization</string>
    <string name="synchronization_across_work_groups">Synchronization across Work Groups</string>
    <string name="synchronization_across_work_groups_description">Use in-order command queue and queue multiple kernel invocations from the host side or use OpenCL event mechanism.\n(To wait on host side until all queued commands have been completed, use clFinish.)</string>
    <string name="state_machine">State Machine</string>
    <string name="energy_formula">Energy Formula</string>
    <string name="pipeline">Pipeline</string>
    <string name="data_dependencies">Data Dependencies</string>
    <string name="read_after_write">Read after write (RAW)</string>
    <string name="read_after_write_description">An instruction j is called data-dependent on a preceding instruction i
        if i provides data that j requires.</string>
    <string name="write_after_read">Write after read (WAR)</string>
    <string name="write_after_read_description">An instruction i is called anti-data-dependent from a subsequent
        instruction j if j describes a memory cell that still has to be read by i.</string>
    <string name="write_after_write">Write after write (WAW)</string>
    <string name="write_after_write_description">Two instructions i and j are called output-dependent if i and j write
        to the same memory cell.</string>
    <string name="example">Example</string>
    <string name="data_dependencies_code">add x12,x2,x3\nsub x4,x5,x12\nand x6,x12,x7\nor x12,x12,x9\nxor x10,x12,x11
    </string>
    <string name="raw_example_description">The last 4 instructions are data-dependent on the add instruction because of x12.</string>
    <string name="war_example_description">sub and and are antidata-dependent on the or command because of x12.</string>
    <string name="waw_example_description">add and or are output-dependent on each other.</string>
    <string name="hierarchy_levels">Hierarchy Levels</string>
    <string name="memory_address">Memory Address</string>
    <string name="linked_list">Linked List</string>
    <string name="triangular_matrix">Triangular Matrix</string>
    <string name="triangular_matrix_description">f [ i , j ] = 1, if access to i is older than access to j, and 0
        otherwise for row index i and column index j.</string>
    <string name="triangular_matrix_initialization">Initialization.</string>
    <string name="triangular_matrix_initialization_description">All entries are set to 1.</string>
    <string name="triangular_matrix_access">Access to k</string>
    <string name="triangular_matrix_access_description"><![CDATA[k becomes the most recent entry. ∀j > k : f[k,j] = 0; ∀i < k : f[i,k] = 1]]></string>
    <string name="triangular_matrix_cache_miss">Cache Miss</string>
    <string name="triangular_matrix_cache_miss_description"><![CDATA[Searching for oldest entry k, for which the following applies.\n∀j > k : f[k,j] = 1 ∧ ∀i < k : f[i,k] = 0]]></string>
    <string name="triangular_matrix_cache_miss_zero">Cache miss, overwrite way 0.</string>
    <string name="access_entry">Access Entry</string>
    <string name="operations">Operations</string>
    <string name="calculator">Calculator</string>
    <string name="static_scheduling">Static Scheduling</string>
    <string name="dynamic_scheduling">Dynamic Scheduling</string>
    <string name="parallelism">Parallelism</string>
    <string name="static_scheduling_parallelism_description">Found and exploited during compilation.</string>
    <string name="dynamic_scheduling_parallelism_description">Found and exploited during execution.</string>
    <string name="execution_order">Execution Order</string>
    <string name="static_scheduling_execution_order_description">In-order: sequence of instructions in memory, apart from jumps; hinders fast execution.</string>
    <string name="dynamic_scheduling_execution_order_description">Out-of-order execution: e.g., scoreboarding, Tomasulo\'s algorithm</string>
    <string name="scorboarding">Scoreboarding</string>
    <string name="scorboarding_description">Stages: issue, read operands, execution, write results\nPhysical registers\nCentral acquisition\nWAR, WAW -> stall></string>
    <string name="tomasulos_algorithm">Tomasulo\'s algorithm</string>
    <string name="tomasulo_algorithm_description">Stages: issue, execution, write results\nLogical registers\nReservation stations\nWAR, WAW solved</string>
    <string name="num_threads_syntax">num_threads (nthreads)</string>
    <string name="num_threads_description">Specifies the number of threads to execute.</string>
    <string name="constructs">Constructs</string>
    <string name="syntax">Syntax</string>
    <string name="cross_bar">Cross Bar</string>
    <string name="cross_bar_description">Circuit of direct connections of all possible node pairs</string>
    <string name="cross_bar_benefits">Communication between nodes via switch is possible in one step.</string>
    <string name="cross_bar_disadvantages">Extremely high hardware complexity</string>
    <string name="switches">Switches</string>
    <string name="omega_network">Omega Network</string>
    <string name="omega_network_description">A circuit of connections of all possible node pairs in several stages.\n
        Multistage interconnection network (MIN).</string>
    <string name="omega_network_benefits">Less hardware complexity than cross bar</string>
    <string name="omega_network_disadvantages">Forwarding of data requires several sub-steps.\nMutual blocking of data paths is possible.</string>
    <string name="benes_network">Benes Network</string>
    <string name="benes_network_description">Consists of two backward-connected butterfly networks\nAll permutations of pairwise node connections can be switched (for offline calculation of routes)\nCan be converted into a redundant tree structure by folding</string>
    <string name="routing_mechanisms">Routing Mechanisms</string>
    <string name="store_and_forward">Store-and-Forward</string>
    <string name="store_and_forward_description">Packages are only forwarded when received completely</string>
    <string name="cut_through_routing">Cut-Through Routing</string>
    <string name="cut_through_routing_description">Flits of a packet are forwarded individually; decision for routing
        to the next node is already made when the packet header is known\n=> Reduced transmission latency similar
        to pipelining
    </string>
    <string name="interconnects">Interconnects</string>
    <string name="topologies">Topologies</string>
    <string name="topologies_description">Connection structure between nodes with communication capabilities (usually
        switches).Influences routing, realibility, throughput, latency, and manufacturing complexity.</string>
    <string name="linear_array">Linear Array</string>
    <string name="degree_of_nodes">Degree of Nodes</string>
    <string name="diameter">Diameter</string>
    <string name="bisection_bandwidth">Bisection Bandwidth</string>
    <string name="evaluation_criteria">Evaluation Criteria</string>
    <string name="node_degree">Node Degree</string>
    <string name="node_degree_description">Number of channels connected to a node or switch</string>
    <string name="network_degree_description">The maximum node degree in the network</string>
    <string name="bisection_bandwidth_description">The minimum number of directed edges in a network between two equal halves of the network with any subdivision, or number of parallel connections between two network halves</string>
    <string name="degree_of_nodes_linear_array">2 for all inner nodes, 1 for edge nodes</string>
    <string name="diameter_description">Length of the maximum shortest path in the network between any two nodes</string>
    <string name="network_degree">Network Degree</string>
    <string name="scalability">Scalability</string>
    <string name="scalability_linear_array">No hardware restriction</string>
    <string name="ring_topology">Ring Topology</string>
    <string name="diameter_ring_topology">⌊N/2⌋ in bidirectional case, N-1 in unidirectional case</string>
    <string name="scalability_ring_topology">No hardware restriction</string>
    <string name="mesh">Mesh (k-D)</string>
    <string name="degree_of_nodes_mesh">k, for corner nodes\n≤2k, for inner nodes</string>
    <string name="torus">Torus</string>
    <string name="tree">Tree</string>
    <string name="degree_of_nodes_tree">1 for leaf/end nodes, 2 for root nodes, 3 for all inner nodes</string>
    <string name="fat_tree">Fat Tree</string>
    <string name="degree_of_nodes_fat_tree">1 for leaf nodes</string>
    <string name="redundant_fat_tree_description">Further improvement of redundancy through replication of communication nodes in the tree and connection to all successor nodes</string>
    <string name="hypercube">Hypercube</string>
    <string name="package_discarding">Discarding the Package</string>
    <string name="package_discarding_description">Network protocol must detect loss and initiate retransmission.</string>
    <string name="buffering_blocked_transmission">Buffering blocked transmission</string>
    <string name="buffering_blocked_transmission_description">In conjunction with cut-through routing: virtual cut-through, buffer size may be problematic</string>
    <string name="blocking_further_transmission">Blocking further transmission</string>
    <string name="blocking_further_transmission_description">In conjunction with cut-through routing: wormhole routing, backlog problematic</string>
    <string name="redirection_of_packets">Redirection of packets</string>
    <string name="redirection_of_packets_description">Requires corresponding routing method</string>
    <string name="routing">Routing</string>
    <string name="redundant_fat_tree">Redundant Fat Tree</string>
    <string name="exclusive_channel_occupation">Exclusive Channel Occupation</string>
    <string name="exclusive_channel_occupation_solutions">Virtual channels (and strict order for channel assignment)\nRestriction of valid routes: Routing procedure itself prevents the creation of cycles (up-down routing, turn-model routing)</string>
    <string name="solutions">Solutions</string>
    <string name="exclusive_channel_occupation_description">For the transmission of messages, physical channels must be occupied exclusively.</string>
    <string name="definition">Definition</string>
    <string name="collision_handling">Collision Handling</string>
    <string name="reduce_cache_misses">Reduce Cache Misses</string>
    <string name="larger_cache_blocks">Larger cache blocks</string>
    <string name="larger_caches_disadvantages">Higher costs, longer cache access time</string>
    <string name="higher_associativity">Higher Associativity</string>
    <string name="higher_associativity_disadvantages">Increases cycle time</string>
    <string name="larger_caches">Larger Caches</string>
    <string name="larger_cache_blocks_disadvantages">Longer loading times</string>
    <string name="reduce_hit_time">Reduce Hit Time</string>
    <string name="small_and_simple_caches">Small and Simple Caches</string>
    <string name="small_and_simple_caches_advantages">Indexing of the tag memory (via index) and comparison with
        requested address: fast if cache is small\nSmall cache can be realized on-chip (of the CPU): shorter signal
        runtimes, more efficient data transfer\nSimpler, i.e., direct mapped: overlapping of data transfer and tag check possible</string>
    <string name="no_address_translation_on_cache_access">No address translation on cache access</string>
    <string name="no_address_translation_on_cache_access_advantages">Virtually indexed, virtually tagged: fast, coherence problems\nVirtually indexed, physically tagged: medium fast\nPhysically indexed, physically tagged: slow, no coherence problems\nPhysically indexed, virtually tagged: theoretically possible, but pointless</string>
    <string name="increase_memory_bandwidth">Increase Memory Bandwidth</string>
    <string name="reduce_miss_penalty">Reduce Miss Penalty</string>
    <string name="multibanked_caches">Multibanked Caches</string>
    <string name="multibanked_caches_description">Blocks are distributed across several memory banks.</string>
    <string name="pipelined_cache_access">Pipelined Cache Access</string>
    <string name="pipelined_cache_access_description">Cache access is distributed over several stages of the pipeline, greater latency in case of incorrect jump prediction</string>
    <string name="nonblocking_caches">Nonblocking Caches</string>
    <string name="nonblocking_caches_description">CPUs with out-of-order completion/execution:\nStopping the CPU in the event of a cache miss is not required.</string>
    <string name="grouping_of_write_buffers">Grouping of Write Buffers</string>
    <string name="grouping_of_write_buffers_description">Writing larger data blocks is more efficient.</string>
    <string name="multiple_cache_levels">Multiple Cache Levels</string>
    <string name="multiple_cache_levels_description">2 cache levels\nL1 cache:\nfast, small, adapted to CPU clock\nL2 cache: large enough to buffer many accesses, can be slower</string>
    <string name="critical_word_first_early_restart_description">If the CPU only needs one value from the cache block, it does not wait until the complete block has been reloaded.</string>
    <string name="critical_word_first_early_restart"><![CDATA[Critical Word First & Early Restart]]></string>
    <string name="prioritization_of_read_over_write_accesses_description">Advantageous if the write buffer contains a value that is requested by the read access</string>
    <string name="prioritization_of_read_over_write_accesses">Prioritization of Read over Write Accesses</string>
    <string name="prefetching">Prefetching</string>
    <string name="prefetching_description">Load elements into cache before they are needed\nAttempt to use memory bandwidth that would otherwise be unused\nCan interfere with regular requests or accesses</string>


</resources>